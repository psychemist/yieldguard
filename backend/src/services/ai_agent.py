import asyncio
import json
import re
import numpy as np
import random
from typing import List, Dict, Optional, Any, Callable
from datetime import datetime, timedelta
import os
from groq import AsyncGroq
from ..models.recommendation import (
    RecommendationResponse, 
    AllocationItem, 
    YieldData, 
    RiskProfile
)

class AgentTool:
    """Base class for agent tools"""
    def __init__(self, name: str, description: str, function: Callable):
        self.name = name
        self.description = description
        self.function = function

class YieldOptimizationAgent:
    """
    Elite AI Agent for DeFi Yield Optimization
    
    TRUE AGENT CAPABILITIES:
    - Autonomous decision making with multi-step reasoning
    - Tool use for data gathering and analysis
    - Goal-oriented behavior with learning
    - Memory and contextual understanding
    - Quality assessment and self-correction
    - Continuous monitoring and adaptation
    """
    
    def __init__(self):
        self.client = AsyncGroq(api_key=os.getenv("GROQ_API_KEY"))
        self.model = "llama-3.3-70b-versatile"
        # self.model = "llama-3.1-70b-versatile"
        # self.model = "mixtral-8x7b-32768",
        
        # AGENT GOALS & OBJECTIVES
        self.goals = {
            "primary": "maximize_risk_adjusted_yield",
            "secondary": ["preserve_capital", "minimize_gas_costs", "optimize_diversification"],
            "success_metrics": ["sharpe_ratio", "max_drawdown", "yield_consistency"]
        }
        
        # AGENT MEMORY SYSTEM
        self.memory = {
            "market_analysis": {},
            "strategy_performance": [],
            "user_preferences": {},
            "learned_patterns": {},
            "decision_history": []
        }
        
        # AGENT TOOLS
        self.tools = self._initialize_agent_tools()
        
        # AGENT STATE
        self.current_plan = None
        self.execution_context = {}
        self.confidence_threshold = 0.8
        
    def _initialize_agent_tools(self) -> Dict[str, AgentTool]:
        """Initialize sophisticated agent tools"""
        return {
            "analyze_market_conditions": AgentTool(
                "analyze_market_conditions",
                "Analyze current DeFi market conditions and trends",
                self._analyze_market_conditions
            ),
            "evaluate_yield_opportunities": AgentTool(
                "evaluate_yield_opportunities", 
                "Evaluate and rank yield opportunities by risk-adjusted returns",
                self._evaluate_yield_opportunities
            ),
            "assess_protocol_risks": AgentTool(
                "assess_protocol_risks",
                "Assess security and risk profiles of DeFi protocols",
                self._assess_protocol_risks
            ),
            "optimize_portfolio_allocation": AgentTool(
                "optimize_portfolio_allocation",
                "Create optimal portfolio allocation using advanced techniques",
                self._optimize_portfolio_allocation
            ),
            "simulate_strategy_outcomes": AgentTool(
                "simulate_strategy_outcomes",
                "Run Monte Carlo simulations on strategy outcomes",
                self._simulate_strategy_outcomes
            ),
            "validate_strategy_quality": AgentTool(
                "validate_strategy_quality",
                "Validate strategy against quality and risk standards",
                self._validate_strategy_quality
            ),
            "monitor_and_adjust": AgentTool(
                "monitor_and_adjust",
                "Monitor strategy performance and make adjustments",
                self._monitor_and_adjust
            )
        }

    async def analyze_and_recommend(
        self,
        capital: float,
        risk_profile: RiskProfile,
        yield_data: List[YieldData],
        gas_data: Dict
    ) -> RecommendationResponse:
        """
        Main agent entry point - autonomous analysis and recommendation
        """
        print(f"ðŸ¤– AI Agent initializing analysis for ${capital:,} with {risk_profile.value} risk profile")
        
        # PHASE 1: Agent Planning
        execution_plan = await self._create_execution_plan(capital, risk_profile, yield_data, gas_data)
        print(f"ðŸ“‹ Agent created execution plan with {len(execution_plan)} steps")
        
        # PHASE 2: Tool-Based Analysis
        analysis_results = await self._execute_analysis_plan(execution_plan)
        
        # PHASE 3: Strategy Synthesis
        strategy = await self._synthesize_strategy(capital, risk_profile, analysis_results)
        
        # Store strategy in context for validation
        self.execution_context["current_strategy"] = strategy
        
        # PHASE 4: Quality Validation
        quality_check = await self._validate_strategy_quality(
            context=self.execution_context,
            objective="validate_strategy_quality",
            strategy=strategy,
            analysis_results=analysis_results
        )
        
        # PHASE 5: Strategy Refinement (if needed)
        if quality_check.get("needs_refinement", False):
            print("ðŸ”„ Agent refining strategy based on quality assessment...")
            strategy = await self._refine_strategy(strategy, quality_check, analysis_results)
        
        # PHASE 6: Memory Update
        await self._update_agent_memory(strategy, analysis_results, quality_check)
        
        # Convert to response format
        return self._convert_to_response(strategy, capital, risk_profile)

    async def _create_execution_plan(
        self, capital: float, risk_profile: RiskProfile, yield_data: List[YieldData], gas_data: Dict
    ) -> List[Dict]:
        """Agent creates its own execution plan"""
        
        planning_context = {
            "capital": capital,
            "risk_profile": risk_profile.value,
            "available_opportunities": len(yield_data),
            "current_gas_price": gas_data.get('standard', 25),
            "agent_memory": len(self.memory.get("decision_history", [])),
            "market_volatility": self._estimate_market_volatility(yield_data)
        }
        
        planning_prompt = f"""
        You are an elite AI agent planning a DeFi yield optimization strategy.
        
        CONTEXT:
        {json.dumps(planning_context, indent=2)}
        
        AGENT GOALS:
        - Primary: {self.goals["primary"]}
        - Secondary: {self.goals["secondary"]}
        
        AVAILABLE TOOLS:
        {list(self.tools.keys())}
        
        Create a strategic execution plan. What tools should you use and in what order?
        
        Respond with JSON:
        {{
            "execution_steps": [
                {{
                    "step": 1,
                    "tool": "analyze_market_conditions",
                    "objective": "Understand current market state",
                    "priority": "high",
                    "expected_outcome": "Market sentiment and volatility assessment"
                }}
            ],
            "risk_management_approach": "Description of risk approach",
            "success_criteria": ["criterion1", "criterion2"],
            "contingency_plans": ["plan1", "plan2"]
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(planning_prompt, "strategic planning")
            plan_data = self._extract_json_from_response(response)
            
            if plan_data and "execution_steps" in plan_data:
                self.current_plan = plan_data
                return plan_data["execution_steps"]
                
        except Exception as e:
            print(f"âš ï¸ Agent planning failed: {e}")
        
        # Fallback plan
        return [
            {"step": 1, "tool": "analyze_market_conditions", "objective": "market_assessment"},
            {"step": 2, "tool": "evaluate_yield_opportunities", "objective": "opportunity_ranking"},
            {"step": 3, "tool": "assess_protocol_risks", "objective": "risk_evaluation"},
            {"step": 4, "tool": "optimize_portfolio_allocation", "objective": "portfolio_construction"}
        ]

    async def _execute_analysis_plan(self, execution_plan: List[Dict]) -> Dict:
        """Execute the agent's analysis plan using tools"""
        
        analysis_results = {}
        
        for step in execution_plan:
            tool_name = step.get("tool")
            objective = step.get("objective", "analysis")
            
            if tool_name in self.tools:
                print(f"ðŸ”§ Agent executing: {tool_name} -> {objective}")
                
                try:
                    # Execute tool with current context
                    if tool_name == "validate_strategy_quality":
                        # Special handling for validation tool
                        tool_result = await self.tools[tool_name].function(
                            context=self.execution_context,
                            objective=objective,
                            strategy=self.execution_context.get("current_strategy"),
                            analysis_results=analysis_results
                        )
                    else:
                        tool_result = await self.tools[tool_name].function(
                            context=self.execution_context,
                            objective=objective
                        )
                    
                    analysis_results[tool_name] = tool_result
                    
                    # Update execution context
                    self.execution_context[tool_name] = tool_result
                    
                    # Agent reflection after each tool
                    should_continue = await self._agent_reflection(step, tool_result)
                    if not should_continue:
                        print("ðŸ›‘ Agent decided to halt execution")
                        break
                        
                except Exception as e:
                    print(f"âŒ Tool {tool_name} failed: {e}")
                    analysis_results[tool_name] = {"error": str(e)}
        
        return analysis_results

    async def _synthesize_strategy(
        self, capital: float, risk_profile: RiskProfile, analysis_results: Dict
    ) -> Dict:
        """Agent synthesizes all analysis into a coherent strategy"""
        
        synthesis_prompt = f"""
        You are an elite AI agent synthesizing analysis results into an optimal DeFi strategy.
        
        INVESTMENT PARAMETERS:
        - Capital: ${capital:,}
        - Risk Profile: {risk_profile.value}
        
        AGENT ANALYSIS RESULTS:
        {json.dumps(analysis_results, default=str, indent=2)}
        
        AGENT GOALS:
        - Primary: {self.goals["primary"]}
        - Success Metrics: {self.goals["success_metrics"]}
        
        AGENT MEMORY (Previous Learnings):
        {json.dumps(self.memory.get("learned_patterns", {}), default=str)}
        
        Synthesize all analysis into an optimal strategy. Think step-by-step:
        1. What did the market analysis reveal?
        2. Which opportunities align with the risk profile?
        3. How should risk be distributed?
        4. What are the key success factors?
        
        Respond with JSON:
        {{
            "strategy_reasoning": {{
                "market_assessment": "Your market analysis conclusion",
                "opportunity_evaluation": "Best opportunities identified",
                "risk_distribution": "How you're managing risk",
                "optimization_logic": "Your optimization approach"
            }},
            "allocations": [
                {{
                    "asset": "USDC",
                    "protocol": "aave-v3",
                    "percentage": 40.0,
                    "expected_yield": 8.5,
                    "risk_score": 0.2,
                    "strategic_rationale": "Why this allocation"
                }}
            ],
            "portfolio_metrics": {{
                "expected_yield": 9.2,
                "risk_score": 0.3,
                "diversification_score": 0.8,
                "sharpe_ratio_estimate": 1.8
            }},
            "monitoring_triggers": ["trigger1", "trigger2"],
            "agent_confidence": 0.85
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(synthesis_prompt, "strategy synthesis")
            strategy_data = self._extract_json_from_response(response)
            
            if strategy_data:
                return strategy_data
                
        except Exception as e:
            print(f"âš ï¸ Strategy synthesis failed: {e}")
        
        # Fallback strategy
        return self._create_fallback_strategy(capital, risk_profile, analysis_results)

    async def _validate_strategy_quality(self, context: Dict = None, objective: str = "analysis", strategy: Dict = None, analysis_results: Dict = None) -> Dict:
        """Tool: Validate strategy against quality and risk standards"""
        print("ðŸ” Agent validating strategy quality...")
        
        # If called as a tool, get strategy from context
        if context and not strategy:
            strategy = context.get("current_strategy", {})
        
        # If no strategy provided, return default validation
        if not strategy:
            return {
                "quality_assessment": {"overall_grade": "B"},
                "needs_refinement": False,
                "confidence_level": 0.7,
                "approval_recommendation": "approve"
            }
        
        validation_prompt = f"""
        You are an elite AI agent validating strategy quality.
        
        STRATEGY TO VALIDATE:
        {json.dumps(strategy, default=str, indent=2)}
        
        ANALYSIS CONTEXT:
        {json.dumps(analysis_results or context or {}, default=str, indent=2)}
        
        QUALITY STANDARDS:
        - Sharpe Ratio: > 1.0
        - Max Drawdown: < 15%
        - Diversification: > 0.7
        - Risk-Return Balance: Optimal for risk profile
        
        Critically evaluate the strategy:
        
        Respond with JSON:
        {{
            "quality_assessment": {{
                "overall_grade": "A/B/C/D/F",
                "sharpe_ratio_evaluation": "assessment",
                "risk_management_evaluation": "assessment",
                "diversification_evaluation": "assessment"
            }},
            "identified_weaknesses": ["weakness1", "weakness2"],
            "improvement_suggestions": ["suggestion1", "suggestion2"],
            "needs_refinement": true/false,
            "confidence_level": 0.0-1.0,
            "approval_recommendation": "approve/refine/reject"
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(validation_prompt, "quality validation")
            validation_data = self._extract_json_from_response(response)
            
            if validation_data:
                return validation_data
                
        except Exception as e:
            print(f"âš ï¸ Quality validation failed: {e}")
        
        # Default validation
        return {
            "quality_assessment": {"overall_grade": "B"},
            "needs_refinement": False,
            "confidence_level": 0.7,
            "approval_recommendation": "approve"
        }

    async def _refine_strategy(self, strategy: Dict, quality_check: Dict, analysis_results: Dict) -> Dict:
        """Agent refines its strategy based on quality assessment"""
        
        refinement_prompt = f"""
        You are an elite AI agent refining your strategy based on quality assessment.
        
        CURRENT STRATEGY:
        {json.dumps(strategy, default=str, indent=2)}
        
        QUALITY ISSUES IDENTIFIED:
        {json.dumps(quality_check.get("identified_weaknesses", []))}
        
        IMPROVEMENT SUGGESTIONS:
        {json.dumps(quality_check.get("improvement_suggestions", []))}
        
        Refine your strategy to address all identified issues:
        
        Respond with JSON (same format as original strategy):
        {{
            "strategy_reasoning": {{
                "refinement_rationale": "What you changed and why",
                "improvements_made": ["improvement1", "improvement2"]
            }},
            "allocations": [refined allocations],
            "portfolio_metrics": {{improved metrics}},
            "agent_confidence": 0.90
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(refinement_prompt, "strategy refinement")
            refined_strategy = self._extract_json_from_response(response)
            
            if refined_strategy:
                return refined_strategy
                
        except Exception as e:
            print(f"âš ï¸ Strategy refinement failed: {e}")
        
        return strategy  # Return original if refinement fails

    async def _update_agent_memory(self, strategy: Dict, analysis_results: Dict, quality_check: Dict):
        """Update agent memory with learnings"""
        
        memory_entry = {
            "timestamp": datetime.now().isoformat(),
            "strategy": strategy,
            "analysis_results": analysis_results,
            "quality_assessment": quality_check,
            "performance_expectation": strategy.get("portfolio_metrics", {}).get("expected_yield", 0)
        }
        
        self.memory["decision_history"].append(memory_entry)
        
        # Extract patterns for learning
        if quality_check.get("overall_grade") in ["A", "B"]:
            # Learn from successful strategies
            success_pattern = {
                "allocation_approach": strategy.get("strategy_reasoning", {}).get("optimization_logic", ""),
                "risk_management": strategy.get("strategy_reasoning", {}).get("risk_distribution", ""),
                "market_conditions": analysis_results.get("analyze_market_conditions", {})
            }
            
            self.memory["learned_patterns"][datetime.now().isoformat()] = success_pattern
        
        print(f"ðŸ§  Agent memory updated with new learnings")

    async def _agent_reflection(self, step: Dict, result: Any) -> bool:
        """Agent reflects on each step and decides whether to continue"""
        
        reflection_prompt = f"""
        You are an AI agent reflecting on your execution step.
        
        STEP EXECUTED:
        {json.dumps(step, indent=2)}
        
        RESULT:
        {json.dumps(result, default=str, indent=2)}
        
        EXECUTION CONTEXT:
        {json.dumps(self.execution_context, default=str, indent=2)}
        
        Should you continue with the plan or make adjustments?
        
        Respond with JSON:
        {{
            "continue_execution": true/false,
            "reflection": "Your analysis of this step",
            "adjustments_needed": "Any plan adjustments",
            "confidence_in_progress": 0.0-1.0
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(reflection_prompt, "agent reflection")
            reflection_data = self._extract_json_from_response(response)
            
            if reflection_data:
                continue_execution = reflection_data.get("continue_execution", True)
                print(f"ðŸ¤” Agent reflection: {reflection_data.get('reflection', 'Continuing...')}")
                return continue_execution
                
        except Exception as e:
            print(f"âš ï¸ Agent reflection failed: {e}")
        
        return True  # Continue by default

    # AGENT TOOL IMPLEMENTATIONS
    async def _analyze_market_conditions(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Analyze current market conditions"""
        print("ðŸ“Š Agent analyzing market conditions...")
        
        # In production, this would call real market APIs
        return {
            "market_sentiment": "bullish",
            "volatility_level": "moderate",
            "gas_conditions": "favorable",
            "defi_tvl_trend": "increasing",
            "yield_environment": "competitive",
            "risk_factors": ["regulatory_uncertainty", "market_volatility"]
        }

    async def _evaluate_yield_opportunities(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Evaluate and rank yield opportunities"""
        print("ðŸ” Agent evaluating yield opportunities...")
        
        # This would integrate with your actual yield data
        return {
            "top_opportunities": [
                {"asset": "USDC", "protocol": "aave-v3", "yield": 8.5, "risk_score": 0.2},
                {"asset": "ETH", "protocol": "compound", "yield": 6.8, "risk_score": 0.4},
                {"asset": "WBTC", "protocol": "aave-v3", "yield": 4.2, "risk_score": 0.3}
            ],
            "opportunity_ranking": "Based on risk-adjusted returns",
            "market_depth": "Sufficient liquidity for target allocation"
        }

    async def _assess_protocol_risks(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Assess protocol security and risks"""
        print("ðŸ”’ Agent assessing protocol risks...")
        
        return {
            "protocol_ratings": {
                "aave-v3": {"security": 0.95, "maturity": 0.9, "risk_grade": "A"},
                "compound": {"security": 0.88, "maturity": 0.85, "risk_grade": "B+"},
                "uniswap-v3": {"security": 0.82, "maturity": 0.8, "risk_grade": "B"}
            },
            "systemic_risks": ["smart_contract_risk", "liquidity_risk"],
            "mitigation_strategies": ["diversification", "position_sizing"]
        }

    async def _optimize_portfolio_allocation(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Optimize portfolio allocation"""
        print("âš–ï¸ Agent optimizing portfolio allocation...")
        
        return {
            "optimization_method": "modern_portfolio_theory_adjusted",
            "allocation_rationale": "Risk-adjusted yield maximization",
            "diversification_score": 0.8,
            "expected_metrics": {
                "portfolio_yield": 7.2,
                "portfolio_risk": 0.3,
                "sharpe_ratio": 1.6
            }
        }

    async def _simulate_strategy_outcomes(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Run Monte Carlo simulations"""
        print("ðŸŽ¯ Agent running strategy simulations...")
        
        return {
            "simulation_results": {
                "expected_return": 7.2,
                "volatility": 12.5,
                "var_95": -8.2,
                "max_drawdown": 11.3,
                "sharpe_ratio": 1.4
            },
            "stress_test_results": {
                "bear_market": -15.2,
                "bull_market": 22.8,
                "sideways_market": 5.1
            },
            "confidence_interval": [3.2, 11.4]
        }

    async def _monitor_and_adjust(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Monitor and adjust strategy"""
        print("ðŸ‘ï¸ Agent setting up monitoring...")
        
        return {
            "monitoring_active": True,
            "adjustment_triggers": ["yield_drop_10pct", "risk_spike", "new_opportunities"],
            "rebalance_frequency": "weekly",
            "alert_thresholds": {"drawdown": 0.1, "yield_deviation": 0.15}
        }

    # UTILITY METHODS
    async def _call_ai_with_retry(self, prompt: str, task: str, max_retries: int = 3) -> str:
        """Call AI with retry logic"""
        for attempt in range(max_retries):
            try:
                response = await asyncio.wait_for(
                    self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": f"You are an elite AI agent performing {task}. Respond with valid JSON only."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.1,
                        max_tokens=2000
                    ),
                    timeout=30.0
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content.strip()
                    
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                await asyncio.sleep(2 ** attempt)  # Exponential backoff
        
        raise Exception(f"Failed to get AI response after {max_retries} attempts")

    def _extract_json_from_response(self, content: str) -> Optional[Dict]:
        """Robust JSON extraction from AI response"""
        if not content:
            return None
            
        # Method 1: Find complete JSON object
        json_start = content.find('{')
        if json_start != -1:
            brace_count = 0
            json_end = json_start
            
            for i, char in enumerate(content[json_start:], json_start):
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        json_end = i + 1
                        break
            
            if json_end > json_start:
                json_str = content[json_start:json_end]
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError:
                    # Try cleaning the JSON
                    cleaned = self._clean_json_string(json_str)
                    try:
                        return json.loads(cleaned)
                    except json.JSONDecodeError:
                        pass
        
        return None

    def _clean_json_string(self, json_str: str) -> str:
        """Clean and fix common JSON formatting issues"""
        json_str = json_str.strip()
        json_str = re.sub(r"'([^']*)':", r'"\1":', json_str)
        json_str = re.sub(r":\s*'([^']*)'", r': "\1"', json_str)
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        return json_str

    def _estimate_market_volatility(self, yield_data: List[YieldData]) -> str:
        """Estimate market volatility from yield data"""
        if not yield_data:
            return "unknown"
        
        yields = [asset.apy for asset in yield_data]
        std_dev = np.std(yields) if len(yields) > 1 else 0
        
        if std_dev < 5:
            return "low"
        elif std_dev < 15:
            return "moderate"
        else:
            return "high"

    def _create_fallback_strategy(self, capital: float, risk_profile: RiskProfile, analysis_results: Dict) -> Dict:
        """Create a fallback strategy if AI fails"""
        return {
            "strategy_reasoning": {
                "market_assessment": "Fallback analysis - moderate conditions",
                "risk_distribution": "Conservative allocation",
                "optimization_logic": "Rule-based fallback"
            },
            "allocations": [
                {
                    "asset": "USDC",
                    "protocol": "aave-v3",
                    "percentage": 60.0,
                    "expected_yield": 6.0,
                    "risk_score": 0.3,
                    "strategic_rationale": "Safe, stable yield"
                },
                {
                    "asset": "ETH",
                    "protocol": "compound",
                    "percentage": 40.0,
                    "expected_yield": 8.0,
                    "risk_score": 0.5,
                    "strategic_rationale": "Growth exposure"
                }
            ],
            "portfolio_metrics": {
                "expected_yield": 6.8,
                "risk_score": 0.38,
                "diversification_score": 0.7,
                "sharpe_ratio_estimate": 1.2
            },
            "agent_confidence": 0.7
        }

    def _convert_to_response(self, strategy: Dict, capital: float, risk_profile: RiskProfile) -> RecommendationResponse:
        """Convert agent strategy to API response format"""
        
        allocations = []
        for alloc in strategy.get("allocations", []):
            allocations.append(AllocationItem(
                asset=alloc["asset"],
                percentage=float(alloc["percentage"]),
                expected_yield=float(alloc["expected_yield"]),
                risk_score=float(alloc.get("risk_score", 0.5))
            ))
        
        portfolio_metrics = strategy.get("portfolio_metrics", {})
        
        return RecommendationResponse(
            timestamp=datetime.now(),
            capital=capital,
            risk_profile=risk_profile,
            allocations=allocations,
            total_expected_yield=float(portfolio_metrics.get("expected_yield", 0)),
            total_risk_score=float(portfolio_metrics.get("risk_score", 0.5)),
            gas_cost_estimate=100.0,
            confidence_score=float(strategy.get("agent_confidence", 0.8))
        )
