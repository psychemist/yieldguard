import asyncio
import json
import re
import numpy as np
import aiohttp
import time
from typing import List, Dict, Optional, Any, Callable
from datetime import datetime, timedelta
import os
from groq import AsyncGroq
from ..models.recommendation import (
    RecommendationResponse, 
    AllocationItem, 
    YieldData, 
    RiskProfile
)

class AgentTool:
    """Base class for agent tools"""
    def __init__(self, name: str, description: str, function: Callable):
        self.name = name
        self.description = description
        self.function = function

class YieldOptimizationAgent:
    """
    PRODUCTION-READY AI Agent for DeFi Yield Optimization
    
    REAL CAPABILITIES:
    - Live market data from DeFiLlama, CoinGecko, and DEX APIs
    - Real-time gas price analysis from Ethereum networks
    - Actual protocol TVL and risk assessment
    - Live yield tracking across major DeFi protocols
    - Monte Carlo simulations with real historical data
    - Comprehensive risk analysis using actual market volatility
    - Multi-model failover system with automatic model switching
    """
    
    def __init__(self):
        self.client = AsyncGroq(api_key=os.getenv("GROQ_API_KEY"))
        
        # PRODUCTION MODEL FAILOVER SYSTEM
        self.available_models = [
            # Groq Models (ordered by preference)
            "llama-3.3-70b-versatile",
            "llama-3.1-70b-versatile", 
            "llama-3.1-8b-instant",
            "llama-3.2-90b-vision-preview",
            "llama-3.2-11b-vision-preview",
            "llama-3.2-3b-preview",
            "llama-3.2-1b-preview",
            "mixtral-8x7b-32768",
            "gemma2-9b-it",
            "gemma-7b-it",
            # Fallback to OpenAI if all Groq models fail
            "openai-gpt-4o-mini",
            "openai-gpt-4o",
            "openai-gpt-3.5-turbo"
        ]
        
        self.current_model = None
        self.model_status = {}  # Track which models are working
        self.rate_limit_cooldowns = {}  # Track cooldown periods for rate-limited models
        self.model_usage_counts = {}  # Track how many times each model has been used
        self.model_performance = {}  # Track success rates for each model
        self.openai_client = None
        
        # PRODUCTION API ENDPOINTS
        self.api_endpoints = {
            "defillama_yields": "https://yields.llama.fi/pools",
            "defillama_protocols": "https://api.llama.fi/protocols",
            "defillama_tvl": "https://api.llama.fi/tvl",
            "coingecko_prices": "https://api.coingecko.com/api/v3/simple/price",
            "coingecko_market": "https://api.coingecko.com/api/v3/coins/markets",
            "etherscan_gas": "https://api.etherscan.io/api",
            "uniswap_v3": "https://api.thegraph.com/subgraphs/name/uniswap/uniswap-v3",
            "aave_v3": "https://api.thegraph.com/subgraphs/name/aave/protocol-v3",
            "compound_v3": "https://api.compound.finance/api/v2/ctoken"
        }
        
        # AGENT GOALS & OBJECTIVES
        self.goals = {
            "primary": "maximize_risk_adjusted_yield",
            "secondary": ["preserve_capital", "minimize_gas_costs", "optimize_diversification"],
            "success_metrics": ["sharpe_ratio", "max_drawdown", "yield_consistency"]
        }
        
        # PRODUCTION MEMORY SYSTEM
        self.memory = {
            "market_data_cache": {},
            "protocol_health_cache": {},
            "gas_history": [],
            "yield_history": {},
            "risk_assessments": {},
            "user_preferences": {},
            "strategy_performance": [],
            "learned_patterns": {},
            "decision_history": []
        }
        
        # PRODUCTION TOOLS
        self.tools = self._initialize_production_tools()
        
        # AGENT STATE
        self.current_plan = None
        self.execution_context = {}
        self.confidence_threshold = 0.8
        self.session = None
        
    # MULTI-MODEL FAILOVER SYSTEM
    async def _get_working_model(self) -> str:
        """Get the next available working model with intelligent failover"""
        current_time = time.time()
        
        # Check if current model is still working and not in cooldown
        if self.current_model and self._is_model_available(self.current_model, current_time):
            return self.current_model
        
        # Test models in order of preference
        for model in self.available_models:
            if self._is_model_available(model, current_time):
                # Test the model with a simple call
                if await self._test_model_availability(model):
                    self.current_model = model
                    print(f"‚úÖ Switched to model: {model}")
                    return model
                else:
                    # Mark model as unavailable for cooldown period
                    self._mark_model_unavailable(model, current_time)
        
        # If all models fail, use the first one as last resort
        fallback_model = self.available_models[0]
        print(f"‚ö†Ô∏è All models failed, using fallback: {fallback_model}")
        return fallback_model
    
    def _is_model_available(self, model: str, current_time: float) -> bool:
        """Check if a model is available (not in cooldown)"""
        if model in self.rate_limit_cooldowns:
            cooldown_until = self.rate_limit_cooldowns[model]
            if current_time < cooldown_until:
                return False
        
        # Check if model has been marked as permanently unavailable
        if model in self.model_status:
            if self.model_status[model] == "unavailable":
                return False
        
        return True
    
    def _mark_model_unavailable(self, model: str, current_time: float):
        """Mark a model as unavailable with cooldown period"""
        if "rate limit" in model or "429" in model:
            # Rate limit - longer cooldown
            self.rate_limit_cooldowns[model] = current_time + 3600  # 1 hour
        else:
            # Other error - shorter cooldown
            self.rate_limit_cooldowns[model] = current_time + 300   # 5 minutes
        
        print(f"‚ùå Model {model} marked unavailable until {datetime.fromtimestamp(self.rate_limit_cooldowns[model])}")
    
    async def _test_model_availability(self, model: str) -> bool:
        """Test if a model is actually working with a simple call"""
        try:
            test_prompt = "Respond with only: OK"
            
            if model.startswith("openai-"):
                # Test OpenAI model
                if not self.openai_client:
                    import openai
                    self.openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                
                response = await self.openai_client.chat.completions.create(
                    model=model.replace("openai-", ""),
                    messages=[{"role": "user", "content": test_prompt}],
                    max_tokens=10,
                    timeout=10
                )
                
                result = response.choices[0].message.content.strip()
                success = "OK" in result
                
            else:
                # Test Groq model
                response = await self.client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": test_prompt}],
                    max_tokens=10,
                    timeout=10
                )
                
                result = response.choices[0].message.content.strip()
                success = "OK" in result
            
            if success:
                # Track successful usage
                self.model_usage_counts[model] = self.model_usage_counts.get(model, 0) + 1
                self.model_status[model] = "available"
                
                # Track performance
                if model not in self.model_performance:
                    self.model_performance[model] = {"success_count": 0, "total_attempts": 0}
                
                self.model_performance[model]["success_count"] += 1
                self.model_performance[model]["total_attempts"] += 1
                
                return True
            else:
                return False
                
        except Exception as e:
            error_msg = str(e).lower()
            
            # Track the error
            if model not in self.model_performance:
                self.model_performance[model] = {"success_count": 0, "total_attempts": 0}
            self.model_performance[model]["total_attempts"] += 1
            
            # Check for rate limit errors
            if "rate limit" in error_msg or "429" in error_msg:
                print(f"‚ö†Ô∏è Rate limit hit for {model}: {e}")
                self._mark_model_unavailable(model, time.time())
                return False
            
            # Check for other errors
            if "not found" in error_msg or "invalid" in error_msg or "deprecated" in error_msg:
                print(f"‚ùå Model {model} appears to be invalid/deprecated: {e}")
                self.model_status[model] = "unavailable"
                return False
            
            print(f"‚ùå Model {model} test failed: {e}")
            return False
    
    async def _call_ai_with_retry(self, prompt: str, operation: str, max_retries: int = 3) -> str:
        """Make AI call with intelligent model failover and retry logic"""
        
        for attempt in range(max_retries):
            try:
                # Get the best available model
                model = await self._get_working_model()
                
                print(f"ü§ñ Attempt {attempt + 1}: Using {model} for {operation}")
                
                if model.startswith("openai-"):
                    # Use OpenAI
                    if not self.openai_client:
                        import openai
                        self.openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                    
                    response = await self.openai_client.chat.completions.create(
                        model=model.replace("openai-", ""),
                        messages=[
                            {"role": "system", "content": "You are an elite DeFi yield optimization agent."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=2000,
                        temperature=0.1,
                        timeout=30
                    )
                    
                    result = response.choices[0].message.content.strip()
                    
                else:
                    # Use Groq
                    response = await self.client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "You are an elite DeFi yield optimization agent."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=2000,
                        temperature=0.1,
                        timeout=30
                    )
                    
                    result = response.choices[0].message.content.strip()
                
                # Success - track performance and return
                if model not in self.model_performance:
                    self.model_performance[model] = {"success_count": 0, "total_attempts": 0}
                
                self.model_performance[model]["success_count"] += 1
                self.model_performance[model]["total_attempts"] += 1
                
                print(f"‚úÖ {operation} successful with {model}")
                return result
                
            except Exception as e:
                error_msg = str(e).lower()
                
                # Track the attempt
                if model not in self.model_performance:
                    self.model_performance[model] = {"success_count": 0, "total_attempts": 0}
                self.model_performance[model]["total_attempts"] += 1
                
                print(f"‚ùå {operation} failed with {model}: {e}")
                
                # Handle rate limits
                if "rate limit" in error_msg or "429" in error_msg:
                    self._mark_model_unavailable(model, time.time())
                    print(f"‚ö†Ô∏è Rate limit hit for {model}, switching models...")
                    continue
                
                # Handle invalid model
                if "not found" in error_msg or "invalid" in error_msg or "deprecated" in error_msg:
                    self.model_status[model] = "unavailable"
                    print(f"‚ùå Model {model} marked as unavailable")
                    continue
                
                # Handle other errors
                if attempt == max_retries - 1:
                    print(f"‚ùå All retry attempts failed for {operation}")
                    raise e
                
                print(f"üîÑ Retrying {operation} with different model...")
                await asyncio.sleep(1)  # Brief delay before retry
        
        raise Exception(f"All models failed for {operation}")
    
    def get_model_status_report(self) -> Dict:
        """Get a detailed report of model performance and availability"""
        current_time = time.time()
        
        report = {
            "current_model": self.current_model,
            "total_models": len(self.available_models),
            "available_models": [],
            "unavailable_models": [],
            "rate_limited_models": [],
            "performance_metrics": {}
        }
        
        for model in self.available_models:
            if self._is_model_available(model, current_time):
                report["available_models"].append(model)
            else:
                if model in self.rate_limit_cooldowns:
                    cooldown_until = datetime.fromtimestamp(self.rate_limit_cooldowns[model])
                    report["rate_limited_models"].append({
                        "model": model,
                        "available_at": cooldown_until.isoformat()
                    })
                else:
                    report["unavailable_models"].append(model)
        
        # Add performance metrics
        for model, perf in self.model_performance.items():
            if perf["total_attempts"] > 0:
                success_rate = perf["success_count"] / perf["total_attempts"]
                report["performance_metrics"][model] = {
                    "success_rate": round(success_rate, 2),
                    "total_attempts": perf["total_attempts"],
                    "successful_calls": perf["success_count"]
                }
        
        return report

    async def _initialize_production_tools(self) -> Dict[str, AgentTool]:
        """Initialize production-ready agent tools"""
        return {
            "fetch_live_market_data": AgentTool(
                "fetch_live_market_data",
                "Fetch live market data from DeFiLlama and CoinGecko",
                self._fetch_live_market_data
            ),
            "analyze_protocol_health": AgentTool(
                "analyze_protocol_health", 
                "Analyze protocol health using live TVL, volume, and security metrics",
                self._analyze_protocol_health
            ),
            "get_real_time_yields": AgentTool(
                "get_real_time_yields",
                "Get real-time yield data from major DeFi protocols",
                self._get_real_time_yields
            ),
            "analyze_gas_optimization": AgentTool(
                "analyze_gas_optimization",
                "Analyze gas prices and optimize transaction timing",
                self._analyze_gas_optimization
            ),
            "calculate_risk_metrics": AgentTool(
                "calculate_risk_metrics",
                "Calculate VaR, Sharpe ratios using real market data",
                self._calculate_risk_metrics
            ),
            "run_monte_carlo_simulation": AgentTool(
                "run_monte_carlo_simulation",
                "Run Monte Carlo simulations with real historical data",
                self._run_monte_carlo_simulation
            ),
            "validate_strategy_quality": AgentTool(
                "validate_strategy_quality",
                "Validate strategy against real market conditions",
                self._validate_strategy_quality
            ),
            "monitor_live_positions": AgentTool(
                "monitor_live_positions",
                "Monitor live positions and market conditions",
                self._monitor_live_positions
            )
        }

    async def _get_session(self) -> aiohttp.ClientSession:
        """Get or create aiohttp session"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30),
                headers={
                    'User-Agent': 'YieldGuard-Agent/1.0',
                    'Accept': 'application/json'
                }
            )
        return self.session

    async def cleanup(self):
        """Cleanup resources"""
        if self.session and not self.session.closed:
            await self.session.close()

    # PRODUCTION TOOL IMPLEMENTATIONS
    async def _fetch_live_market_data(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Fetch live market data from multiple sources"""
        print("üåê Fetching live market data from DeFiLlama and CoinGecko...")
        
        session = await self._get_session()
        market_data = {}
        
        try:
            # 1. Get DeFiLlama protocol data
            async with session.get(self.api_endpoints["defillama_protocols"]) as response:
                if response.status == 200:
                    protocols = await response.json()
                    market_data["protocols"] = protocols[:50]  # Top 50 protocols
                    
            # 2. Get current TVL data
            async with session.get(self.api_endpoints["defillama_tvl"]) as response:
                if response.status == 200:
                    tvl_data = await response.json()
                    market_data["total_tvl"] = tvl_data
                    
            # 3. Get major crypto prices
            price_params = {
                "ids": "ethereum,bitcoin,usd-coin,dai,chainlink,aave,compound-governance-token",
                "vs_currencies": "usd",
                "include_24hr_change": "true",
                "include_market_cap": "true"
            }
            async with session.get(self.api_endpoints["coingecko_prices"], params=price_params) as response:
                if response.status == 200:
                    prices = await response.json()
                    market_data["prices"] = prices
                    
            # 4. Get market data for volatility analysis
            market_params = {
                "vs_currency": "usd",
                "order": "market_cap_desc",
                "per_page": 20,
                "page": 1,
                "sparkline": "false",
                "price_change_percentage": "1h,24h,7d"
            }
            async with session.get(self.api_endpoints["coingecko_market"], params=market_params) as response:
                if response.status == 200:
                    market_overview = await response.json()
                    market_data["market_overview"] = market_overview
                    
            # Cache the data
            self.memory["market_data_cache"] = {
                "data": market_data,
                "timestamp": datetime.now().isoformat(),
                "ttl": 300  # 5 minutes
            }
            
            # Calculate market sentiment
            market_sentiment = self._calculate_market_sentiment(market_data)
            market_data["sentiment"] = market_sentiment
            
            print(f"‚úÖ Fetched live data for {len(market_data.get('protocols', []))} protocols")
            return market_data
            
        except Exception as e:
            print(f"‚ùå Error fetching live market data: {e}")
            return {"error": str(e), "fallback": "using_cached_data"}

    async def _analyze_protocol_health(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Analyze protocol health using live data"""
        print("üè• Analyzing protocol health with live TVL and security metrics...")
        
        session = await self._get_session()
        protocol_health = {}
        
        try:
            # Get yields data to analyze protocol performance
            async with session.get(self.api_endpoints["defillama_yields"]) as response:
                if response.status == 200:
                    yields_data = await response.json()
                    
                    # Analyze top protocols
                    protocol_analysis = {}
                    for pool in yields_data["data"][:100]:  # Top 100 pools
                        protocol = pool.get("project", "unknown")
                        
                        if protocol not in protocol_analysis:
                            protocol_analysis[protocol] = {
                                "pools": [],
                                "total_tvl": 0,
                                "avg_apy": 0,
                                "risk_score": 0,
                                "pool_count": 0
                            }
                        
                        protocol_analysis[protocol]["pools"].append({
                            "chain": pool.get("chain"),
                            "symbol": pool.get("symbol"),
                            "tvl": pool.get("tvlUsd", 0),
                            "apy": pool.get("apy", 0),
                            "apyBase": pool.get("apyBase", 0),
                            "apyReward": pool.get("apyReward", 0),
                            "stablecoin": pool.get("stablecoin", False),
                            "ilRisk": pool.get("ilRisk", "no"),
                            "exposure": pool.get("exposure", "single")
                        })
                        
                        protocol_analysis[protocol]["total_tvl"] += pool.get("tvlUsd", 0)
                        protocol_analysis[protocol]["pool_count"] += 1
                    
                    # Calculate health metrics for each protocol
                    for protocol, data in protocol_analysis.items():
                        if data["pool_count"] > 0:
                            data["avg_apy"] = sum(p["apy"] for p in data["pools"]) / data["pool_count"]
                            
                            # Risk assessment based on multiple factors
                            risk_factors = []
                            
                            # TVL risk (lower TVL = higher risk)
                            if data["total_tvl"] < 1000000:  # < $1M
                                risk_factors.append("low_tvl")
                            elif data["total_tvl"] < 10000000:  # < $10M
                                risk_factors.append("medium_tvl")
                            
                            # IL risk assessment
                            il_risk_pools = [p for p in data["pools"] if p["ilRisk"] != "no"]
                            if len(il_risk_pools) / data["pool_count"] > 0.5:
                                risk_factors.append("high_il_risk")
                            
                            # Diversification risk
                            single_exposure = [p for p in data["pools"] if p["exposure"] == "single"]
                            if len(single_exposure) / data["pool_count"] > 0.7:
                                risk_factors.append("concentrated_exposure")
                            
                            # Calculate final risk score
                            base_risk = 0.3
                            for factor in risk_factors:
                                if factor == "low_tvl":
                                    base_risk += 0.3
                                elif factor == "medium_tvl":
                                    base_risk += 0.1
                                elif factor == "high_il_risk":
                                    base_risk += 0.2
                                elif factor == "concentrated_exposure":
                                    base_risk += 0.15
                            
                            data["risk_score"] = min(base_risk, 1.0)
                            data["risk_factors"] = risk_factors
                    
                    protocol_health = protocol_analysis
                    
            # Cache the analysis
            self.memory["protocol_health_cache"] = {
                "data": protocol_health,
                "timestamp": datetime.now().isoformat(),
                "ttl": 600  # 10 minutes
            }
            
            print(f"‚úÖ Analyzed health for {len(protocol_health)} protocols")
            return protocol_health
            
        except Exception as e:
            print(f"‚ùå Error analyzing protocol health: {e}")
            return {"error": str(e)}

    async def _get_real_time_yields(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Get real-time yield data from major DeFi protocols"""
        print("üìä Fetching real-time yields from major DeFi protocols...")
        
        session = await self._get_session()
        yields_data = {}
        
        try:
            # Get comprehensive yields data
            async with session.get(self.api_endpoints["defillama_yields"]) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    # Filter and categorize yields
                    stable_yields = []
                    crypto_yields = []
                    lp_yields = []
                    
                    for pool in data["data"]:
                        pool_info = {
                            "protocol": pool.get("project"),
                            "chain": pool.get("chain"),
                            "symbol": pool.get("symbol"),
                            "tvl": pool.get("tvlUsd", 0),
                            "apy": pool.get("apy", 0),
                            "apyBase": pool.get("apyBase", 0),
                            "apyReward": pool.get("apyReward", 0),
                            "stablecoin": pool.get("stablecoin", False),
                            "ilRisk": pool.get("ilRisk", "no"),
                            "exposure": pool.get("exposure", "single"),
                            "poolMeta": pool.get("poolMeta", ""),
                            "url": pool.get("url", "")
                        }
                        
                        # Only include pools with reasonable TVL and APY
                        if pool_info["tvl"] > 100000 and pool_info["apy"] > 0 and pool_info["apy"] < 1000:
                            if pool_info["stablecoin"]:
                                stable_yields.append(pool_info)
                            elif pool_info["ilRisk"] != "no":
                                lp_yields.append(pool_info)
                            else:
                                crypto_yields.append(pool_info)
                    
                    # Sort by TVL (descending) and take top options
                    stable_yields.sort(key=lambda x: x["tvl"], reverse=True)
                    crypto_yields.sort(key=lambda x: x["tvl"], reverse=True)
                    lp_yields.sort(key=lambda x: x["tvl"], reverse=True)
                    
                    yields_data = {
                        "stable_yields": stable_yields[:20],
                        "crypto_yields": crypto_yields[:20],
                        "lp_yields": lp_yields[:20],
                        "total_pools": len(data["data"]),
                        "timestamp": datetime.now().isoformat()
                    }
                    
            # Cache yields data
            self.memory["yield_history"][datetime.now().isoformat()] = yields_data
            
            print(f"‚úÖ Fetched {len(yields_data.get('stable_yields', []))} stable, {len(yields_data.get('crypto_yields', []))} crypto, {len(yields_data.get('lp_yields', []))} LP yields")
            return yields_data
            
        except Exception as e:
            print(f"‚ùå Error fetching real-time yields: {e}")
            return {"error": str(e)}

    async def _analyze_gas_optimization(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Analyze gas prices and optimize transaction timing"""
        print("‚õΩ Analyzing real-time gas prices and optimization strategies...")
        
        session = await self._get_session()
        gas_analysis = {}
        
        try:
            # Get current gas prices from Etherscan
            gas_params = {
                "module": "gastracker",
                "action": "gasoracle",
                "apikey": os.getenv("ETHERSCAN_API_KEY")
            }
            
            async with session.get(self.api_endpoints["etherscan_gas"], params=gas_params) as response:
                if response.status == 200:
                    gas_data = await response.json()
                    
                    if gas_data["status"] == "1":
                        current_gas = gas_data["result"]
                        
                        gas_analysis = {
                            "current_gas": {
                                "safe": int(current_gas["SafeGasPrice"]),
                                "standard": int(current_gas["ProposeGasPrice"]),
                                "fast": int(current_gas["FastGasPrice"])
                            },
                            "timestamp": datetime.now().isoformat()
                        }
                        
                        # Store in history for trend analysis
                        self.memory["gas_history"].append(gas_analysis)
                        
                        # Keep only last 100 entries
                        if len(self.memory["gas_history"]) > 100:
                            self.memory["gas_history"] = self.memory["gas_history"][-100:]
                        
                        # Analyze trends if we have history
                        if len(self.memory["gas_history"]) > 10:
                            recent_gas = [g["current_gas"]["standard"] for g in self.memory["gas_history"][-10:]]
                            
                            trend_analysis = {
                                "avg_last_10": sum(recent_gas) / len(recent_gas),
                                "current_vs_avg": current_gas["ProposeGasPrice"] - (sum(recent_gas) / len(recent_gas)),
                                "volatility": np.std(recent_gas) if len(recent_gas) > 1 else 0,
                                "trend": "increasing" if recent_gas[-1] > recent_gas[0] else "decreasing"
                            }
                            
                            gas_analysis["trend_analysis"] = trend_analysis
                            
                            # Optimization recommendations
                            recommendations = []
                            
                            if trend_analysis["current_vs_avg"] > 5:
                                recommendations.append("Consider waiting - gas prices above recent average")
                            elif trend_analysis["current_vs_avg"] < -5:
                                recommendations.append("Good time to execute - gas prices below recent average")
                            
                            if trend_analysis["trend"] == "decreasing":
                                recommendations.append("Gas trend is decreasing - consider waiting for lower prices")
                            elif trend_analysis["trend"] == "increasing":
                                recommendations.append("Gas trend is increasing - consider executing soon")
                            
                            # Cost estimation for common operations
                            cost_estimates = {
                                "simple_transfer": current_gas["SafeGasPrice"] * 21000,
                                "erc20_transfer": current_gas["SafeGasPrice"] * 65000,
                                "uniswap_swap": current_gas["SafeGasPrice"] * 150000,
                                "aave_deposit": current_gas["SafeGasPrice"] * 200000,
                                "compound_supply": current_gas["SafeGasPrice"] * 250000
                            }
                            
                            gas_analysis["cost_estimates_gwei"] = cost_estimates
                            gas_analysis["recommendations"] = recommendations
            
            print(f"‚úÖ Gas analysis complete - Current: {gas_analysis.get('current_gas', {}).get('standard', 0)} gwei")
            return gas_analysis
            
        except Exception as e:
            print(f"‚ùå Error analyzing gas prices: {e}")
            return {"error": str(e)}

    async def _calculate_risk_metrics(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Calculate VaR, Sharpe ratios using real market data"""
        print("üìà Calculating risk metrics using real market data...")
        
        session = await self._get_session()
        risk_metrics = {}
        
        try:
            # Get historical price data for major assets
            assets = ["ethereum", "bitcoin", "usd-coin", "dai", "chainlink", "aave"]
            
            for asset in assets:
                params = {
                    "id": asset,
                    "vs_currency": "usd",
                    "days": "90",  # 90 days of data
                    "interval": "daily"
                }
                
                async with session.get(f"https://api.coingecko.com/api/v3/coins/{asset}/market_chart", params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        prices = [price[1] for price in data["prices"]]
                        
                        # Calculate returns
                        returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
                        
                        if len(returns) > 0:
                            # Calculate risk metrics
                            mean_return = np.mean(returns)
                            volatility = np.std(returns)
                            
                            # Sharpe ratio (assuming risk-free rate of 2% annually)
                            risk_free_rate = 0.02 / 365  # Daily risk-free rate
                            sharpe_ratio = (mean_return - risk_free_rate) / volatility if volatility > 0 else 0
                            
                            # VaR (Value at Risk) at 95% confidence
                            var_95 = np.percentile(returns, 5)
                            
                            # Maximum drawdown calculation
                            cumulative_returns = np.cumprod([1 + r for r in returns])
                            running_max = np.maximum.accumulate(cumulative_returns)
                            drawdown = (cumulative_returns - running_max) / running_max
                            max_drawdown = np.min(drawdown)
                            
                            risk_metrics[asset] = {
                                "mean_daily_return": mean_return,
                                "daily_volatility": volatility,
                                "annualized_volatility": volatility * np.sqrt(365),
                                "sharpe_ratio": sharpe_ratio,
                                "var_95": var_95,
                                "max_drawdown": max_drawdown,
                                "current_price": prices[-1]
                            }
                
                # Rate limiting
                await asyncio.sleep(0.1)
            
            # Calculate correlation matrix
            if len(risk_metrics) > 1:
                correlation_matrix = {}
                asset_names = list(risk_metrics.keys())
                
                for i, asset1 in enumerate(asset_names):
                    for j, asset2 in enumerate(asset_names):
                        if i != j:
                            # This is a simplified correlation calculation
                            # In production, you'd use actual historical returns
                            vol1 = risk_metrics[asset1]["daily_volatility"]
                            vol2 = risk_metrics[asset2]["daily_volatility"]
                            
                            # Estimate correlation based on asset types
                            if asset1 in ["usd-coin", "dai"] and asset2 in ["usd-coin", "dai"]:
                                correlation = 0.95  # High correlation for stablecoins
                            elif asset1 in ["ethereum", "bitcoin"] and asset2 in ["ethereum", "bitcoin"]:
                                correlation = 0.7   # Moderate correlation for crypto
                            else:
                                correlation = 0.3   # Low correlation otherwise
                            
                            correlation_matrix[f"{asset1}_{asset2}"] = correlation
                
                risk_metrics["correlations"] = correlation_matrix
            
            # Cache risk metrics
            self.memory["risk_assessments"] = {
                "data": risk_metrics,
                "timestamp": datetime.now().isoformat(),
                "ttl": 3600  # 1 hour
            }
            
            print(f"‚úÖ Risk metrics calculated for {len(risk_metrics)} assets")
            return risk_metrics
            
        except Exception as e:
            print(f"‚ùå Error calculating risk metrics: {e}")
            return {"error": str(e)}

    async def _run_monte_carlo_simulation(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Run Monte Carlo simulations with real historical data"""
        print("üé≤ Running Monte Carlo simulations with real market data...")
        
        try:
            # Get current strategy from context
            strategy = context.get("current_strategy", {}) if context else {}
            allocations = strategy.get("allocations", [])
            
            if not allocations:
                return {"error": "No strategy allocations provided"}
            
            # Get risk metrics from cache or calculate them
            risk_data = self.memory.get("risk_assessments", {}).get("data", {})
            
            if not risk_data:
                # Calculate risk metrics if not cached
                risk_data = await self._calculate_risk_metrics()
            
            # Run Monte Carlo simulation
            num_simulations = 10000
            time_horizon = 252  # 1 year in trading days
            
            portfolio_returns = []
            
            for simulation in range(num_simulations):
                portfolio_return = 0
                
                for allocation in allocations:
                    asset_name = allocation.get("asset", "").lower()
                    percentage = allocation.get("percentage", 0) / 100
                    
                    # Map asset names to risk data keys
                    risk_key = None
                    if asset_name in ["usdc", "usd-coin"]:
                        risk_key = "usd-coin"
                    elif asset_name in ["dai"]:
                        risk_key = "dai"
                    elif asset_name in ["eth", "ethereum"]:
                        risk_key = "ethereum"
                    elif asset_name in ["btc", "bitcoin", "wbtc"]:
                        risk_key = "bitcoin"
                    elif asset_name in ["link", "chainlink"]:
                        risk_key = "chainlink"
                    elif asset_name in ["aave"]:
                        risk_key = "aave"
                    
                    if risk_key and risk_key in risk_data:
                        asset_risk = risk_data[risk_key]
                        
                        # Generate random returns based on historical data
                        daily_returns = np.random.normal(
                            asset_risk["mean_daily_return"],
                            asset_risk["daily_volatility"],
                            time_horizon
                        )
                        
                        # Calculate cumulative return
                        cumulative_return = np.prod(1 + daily_returns) - 1
                        portfolio_return += cumulative_return * percentage
                    else:
                        # Fallback for unknown assets
                        daily_returns = np.random.normal(0.0001, 0.02, time_horizon)  # Conservative assumption
                        cumulative_return = np.prod(1 + daily_returns) - 1
                        portfolio_return += cumulative_return * percentage
                
                portfolio_returns.append(portfolio_return)
            
            # Calculate simulation statistics
            portfolio_returns = np.array(portfolio_returns)
            
            simulation_results = {
                "num_simulations": num_simulations,
                "time_horizon_days": time_horizon,
                "expected_return": float(np.mean(portfolio_returns)),
                "volatility": float(np.std(portfolio_returns)),
                "sharpe_ratio": float(np.mean(portfolio_returns) / np.std(portfolio_returns)) if np.std(portfolio_returns) > 0 else 0,
                "var_95": float(np.percentile(portfolio_returns, 5)),
                "var_99": float(np.percentile(portfolio_returns, 1)),
                "cvar_95": float(np.mean(portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)])),
                "max_loss": float(np.min(portfolio_returns)),
                "max_gain": float(np.max(portfolio_returns)),
                "probability_positive": float(np.sum(portfolio_returns > 0) / len(portfolio_returns)),
                "probability_loss_over_10pct": float(np.sum(portfolio_returns < -0.1) / len(portfolio_returns)),
                "probability_loss_over_20pct": float(np.sum(portfolio_returns < -0.2) / len(portfolio_returns)),
                "percentiles": {
                    "5th": float(np.percentile(portfolio_returns, 5)),
                    "10th": float(np.percentile(portfolio_returns, 10)),
                    "25th": float(np.percentile(portfolio_returns, 25)),
                    "50th": float(np.percentile(portfolio_returns, 50)),
                    "75th": float(np.percentile(portfolio_returns, 75)),
                    "90th": float(np.percentile(portfolio_returns, 90)),
                    "95th": float(np.percentile(portfolio_returns, 95))
                }
            }
            
            print(f"‚úÖ Monte Carlo simulation complete - Expected return: {simulation_results['expected_return']:.2%}")
            return simulation_results
            
        except Exception as e:
            print(f"‚ùå Error running Monte Carlo simulation: {e}")
            return {"error": str(e)}

    async def _validate_strategy_quality(self, context: Dict = None, objective: str = "analysis", strategy: Dict = None, analysis_results: Dict = None) -> Dict:
        """Tool: Validate strategy against real market conditions"""
        print("üîç Validating strategy quality against real market conditions...")
        
        try:
            # Get strategy from context if not provided
            if not strategy and context:
                strategy = context.get("current_strategy", {})
            
            if not strategy:
                return {"error": "No strategy provided for validation"}
            
            # Run Monte Carlo simulation for this strategy
            simulation_results = await self._run_monte_carlo_simulation(context={"current_strategy": strategy})
            
            if "error" in simulation_results:
                return {"error": f"Simulation failed: {simulation_results['error']}"}
            
            # Validate against institutional standards
            validation_results = {
                "quality_assessment": {},
                "identified_weaknesses": [],
                "improvement_suggestions": [],
                "needs_refinement": False,
                "confidence_level": 0.8,
                "approval_recommendation": "approve"
            }
            
            # 1. Sharpe Ratio Assessment
            sharpe_ratio = simulation_results.get("sharpe_ratio", 0)
            if sharpe_ratio > 1.5:
                validation_results["quality_assessment"]["sharpe_ratio_evaluation"] = "Excellent"
            elif sharpe_ratio > 1.0:
                validation_results["quality_assessment"]["sharpe_ratio_evaluation"] = "Good"
            elif sharpe_ratio > 0.5:
                validation_results["quality_assessment"]["sharpe_ratio_evaluation"] = "Acceptable"
            else:
                validation_results["quality_assessment"]["sharpe_ratio_evaluation"] = "Poor"
                validation_results["identified_weaknesses"].append("Low Sharpe ratio")
                validation_results["improvement_suggestions"].append("Increase yield or reduce risk")
            
            # 2. VaR Assessment
            var_95 = abs(simulation_results.get("var_95", 0))
            if var_95 > 0.15:  # More than 15% potential loss
                validation_results["identified_weaknesses"].append("High Value at Risk")
                validation_results["improvement_suggestions"].append("Reduce position sizes or add hedging")
            
            # 3. Probability of Loss Assessment
            prob_loss_10pct = simulation_results.get("probability_loss_over_10pct", 0)
            if prob_loss_10pct > 0.1:  # More than 10% chance of >10% loss
                validation_results["identified_weaknesses"].append("High probability of significant losses")
                validation_results["improvement_suggestions"].append("Diversify into more stable assets")
            
            # 4. Diversification Assessment
            allocations = strategy.get("allocations", [])
            if len(allocations) < 3:
                validation_results["identified_weaknesses"].append("Insufficient diversification")
                validation_results["improvement_suggestions"].append("Add more asset classes")
            
            # Check for concentration risk
            max_allocation = max([alloc.get("percentage", 0) for alloc in allocations]) if allocations else 0
            if max_allocation > 60:
                validation_results["identified_weaknesses"].append("High concentration risk")
                validation_results["improvement_suggestions"].append("Reduce maximum position size")
            
            # 5. Overall Grade Calculation
            score = 0
            if sharpe_ratio > 1.0:
                score += 25
            if var_95 < 0.15:
                score += 25
            if prob_loss_10pct < 0.1:
                score += 25
            if len(allocations) >= 3 and max_allocation <= 60:
                score += 25
            
            if score >= 90:
                validation_results["quality_assessment"]["overall_grade"] = "A"
            elif score >= 80:
                validation_results["quality_assessment"]["overall_grade"] = "B"
            elif score >= 70:
                validation_results["quality_assessment"]["overall_grade"] = "C"
            else:
                validation_results["quality_assessment"]["overall_grade"] = "D"
                validation_results["needs_refinement"] = True
                validation_results["approval_recommendation"] = "refine"
            
            # Set confidence level based on data quality
            if len(validation_results["identified_weaknesses"]) == 0:
                validation_results["confidence_level"] = 0.95
            elif len(validation_results["identified_weaknesses"]) <= 2:
                validation_results["confidence_level"] = 0.8
            else:
                validation_results["confidence_level"] = 0.6
            
        except Exception as e:
            print(f"‚ùå Error validating strategy: {e}")
            return {"error": str(e)}

    async def _monitor_live_positions(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Monitor live positions and market conditions"""
        print("üëÅÔ∏è Setting up live position monitoring...")
        
        try:
            # Get current strategy
            strategy = context.get("current_strategy", {}) if context else {}
            allocations = strategy.get("allocations", [])
            
            monitoring_config = {
                "positions": [],
                "alert_thresholds": {
                    "yield_drop": 0.15,  # 15% drop in yield
                    "tvl_drop": 0.25,    # 25% drop in TVL
                    "gas_spike": 50,     # Gas price spike above 50 gwei
                    "volatility_spike": 0.05  # 5% daily volatility spike
                },
                "monitoring_frequency": "15_minutes",
                "notification_channels": ["console", "memory"],
                "active": True
            }
            
            # Set up monitoring for each position
            for allocation in allocations:
                position_monitor = {
                    "asset": allocation.get("asset"),
                    "protocol": allocation.get("protocol"),
                    "percentage": allocation.get("percentage"),
                    "expected_yield": allocation.get("expected_yield"),
                    "current_yield": None,
                    "last_check": datetime.now().isoformat(),
                    "alerts": []
                }
                
                monitoring_config["positions"].append(position_monitor)
            
            # Store monitoring config in memory
            self.memory["monitoring_active"] = monitoring_config
            
            print(f"‚úÖ Live monitoring active for {len(allocations)} positions")
            return monitoring_config
            
        except Exception as e:
            print(f"‚ùå Error setting up monitoring: {e}")
            return {"error": str(e)}

    def _calculate_market_sentiment(self, market_data: Dict) -> Dict:
        """Calculate market sentiment from real data"""
        try:
            sentiment_score = 0
            factors = []
            
            # Analyze price changes
            prices = market_data.get("prices", {})
            for asset, data in prices.items():
                if "usd_24h_change" in data:
                    change = data["usd_24h_change"]
                    if change > 5:
                        sentiment_score += 1
                        factors.append(f"{asset} up {change:.1f}%")
                    elif change < -5:
                        sentiment_score -= 1
                        factors.append(f"{asset} down {change:.1f}%")
            
            # Analyze market overview
            market_overview = market_data.get("market_overview", [])
            if market_overview:
                positive_24h = sum(1 for coin in market_overview if coin.get("price_change_percentage_24h", 0) > 0)
                negative_24h = len(market_overview) - positive_24h
                
                if positive_24h > negative_24h:
                    sentiment_score += 1
                    factors.append("More assets positive than negative")
                elif negative_24h > positive_24h:
                    sentiment_score -= 1
                    factors.append("More assets negative than positive")
            
            # Determine sentiment
            if sentiment_score > 2:
                sentiment = "bullish"
            elif sentiment_score < -2:
                sentiment = "bearish"
            else:
                sentiment = "neutral"
            
            return {
                "sentiment": sentiment,
                "score": sentiment_score,
                "factors": factors,
                "confidence": min(abs(sentiment_score) / 5, 1.0)
            }
            
        except Exception as e:
            return {"sentiment": "neutral", "error": str(e)}

    # AGENT TOOL IMPLEMENTATIONS
    async def _analyze_market_conditions(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Analyze current market conditions"""
        print("üìä Agent analyzing market conditions...")
        
        # In production, this would call real market APIs
        return {
            "market_sentiment": "bullish",
            "volatility_level": "moderate",
            "gas_conditions": "favorable",
            "defi_tvl_trend": "increasing",
            "yield_environment": "competitive",
            "risk_factors": ["regulatory_uncertainty", "market_volatility"]
        }

    async def _evaluate_yield_opportunities(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Evaluate and rank yield opportunities"""
        print("üîç Agent evaluating yield opportunities...")
        
        # This would integrate with your actual yield data
        return {
            "top_opportunities": [
                {"asset": "USDC", "protocol": "aave-v3", "yield": 8.5, "risk_score": 0.2},
                {"asset": "ETH", "protocol": "compound", "yield": 6.8, "risk_score": 0.4},
                {"asset": "WBTC", "protocol": "aave-v3", "yield": 4.2, "risk_score": 0.3}
            ],
            "opportunity_ranking": "Based on risk-adjusted returns",
            "market_depth": "Sufficient liquidity for target allocation"
        }

    async def _assess_protocol_risks(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Assess protocol security and risks"""
        print("üîí Agent assessing protocol risks...")
        
        return {
            "protocol_ratings": {
                "aave-v3": {"security": 0.95, "maturity": 0.9, "risk_grade": "A"},
                "compound": {"security": 0.88, "maturity": 0.85, "risk_grade": "B+"},
                "uniswap-v3": {"security": 0.82, "maturity": 0.8, "risk_grade": "B"}
            },
            "systemic_risks": ["smart_contract_risk", "liquidity_risk"],
            "mitigation_strategies": ["diversification", "position_sizing"]
        }

    async def _optimize_portfolio_allocation(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Optimize portfolio allocation"""
        print("‚öñÔ∏è Agent optimizing portfolio allocation...")
        
        return {
            "optimization_method": "modern_portfolio_theory_adjusted",
            "allocation_rationale": "Risk-adjusted yield maximization",
            "diversification_score": 0.8,
            "expected_metrics": {
                "portfolio_yield": 7.2,
                "portfolio_risk": 0.3,
                "sharpe_ratio": 1.6
            }
        }

    async def _simulate_strategy_outcomes(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Run Monte Carlo simulations"""
        print("üéØ Agent running strategy simulations...")
        
        return {
            "simulation_results": {
                "expected_return": 7.2,
                "volatility": 12.5,
                "var_95": -8.2,
                "max_drawdown": 11.3,
                "sharpe_ratio": 1.4
            },
            "stress_test_results": {
                "bear_market": -15.2,
                "bull_market": 22.8,
                "sideways_market": 5.1
            },
            "confidence_interval": [3.2, 11.4]
        }

    async def _monitor_and_adjust(self, context: Dict = None, objective: str = "analysis") -> Dict:
        """Tool: Monitor and adjust strategy"""
        print("üëÅÔ∏è Agent setting up monitoring...")
        
        return {
            "monitoring_active": True,
            "adjustment_triggers": ["yield_drop_10pct", "risk_spike", "new_opportunities"],
            "rebalance_frequency": "weekly",
            "alert_thresholds": {"drawdown": 0.1, "yield_deviation": 0.15}
        }

    # AGENT CORE LOGIC
    async def analyze_and_recommend(
        self,
        capital: float,
        risk_profile: RiskProfile,
        yield_data: List[YieldData],
        gas_data: Dict
    ) -> RecommendationResponse:
        """
        Main agent entry point - autonomous analysis and recommendation
        """
        print(f"ü§ñ AI Agent initializing analysis for ${capital:,} with {risk_profile.value} risk profile")
        
        try:
            # PHASE 1: Agent Planning
            execution_plan = await self._create_execution_plan(capital, risk_profile, yield_data, gas_data)
            print(f"üìã Agent created execution plan with {len(execution_plan)} steps")
            
            # PHASE 2: Tool-Based Analysis
            analysis_results = await self._execute_analysis_plan(execution_plan)
            
            # PHASE 3: Strategy Synthesis
            strategy = await self._synthesize_strategy(capital, risk_profile, analysis_results)
            
            # Store strategy in context for validation
            self.execution_context["current_strategy"] = strategy
            
            # PHASE 4: Quality Validation
            quality_check = await self._validate_strategy_quality(
                context=self.execution_context,
                objective="validate_strategy_quality",
                strategy=strategy,
                analysis_results=analysis_results
            )
            
            # PHASE 5: Strategy Refinement (if needed)
            if quality_check.get("needs_refinement", False):
                print("üîÑ Agent refining strategy based on quality assessment...")
                strategy = await self._refine_strategy(strategy, quality_check, analysis_results)
            
            # PHASE 6: Memory Update
            await self._update_agent_memory(strategy, analysis_results, quality_check)
            
            # Convert to response format
            return self._convert_to_response(strategy, capital, risk_profile)
            
        except Exception as e:
            print(f"‚ùå Agent analysis failed: {e}")
            # Return fallback strategy
            fallback_strategy = self._create_fallback_strategy(capital, risk_profile, {})
            return self._convert_to_response(fallback_strategy, capital, risk_profile)
        finally:
            # Cleanup resources
            await self.cleanup()

    async def _create_execution_plan(
        self, capital: float, risk_profile: RiskProfile, yield_data: List[YieldData], gas_data: Dict
    ) -> List[Dict]:
        """Agent creates its own execution plan"""
        
        planning_context = {
            "capital": capital,
            "risk_profile": risk_profile.value,
            "available_opportunities": len(yield_data),
            "current_gas_price": gas_data.get('standard', 25),
            "agent_memory": len(self.memory.get("decision_history", [])),
            "market_volatility": self._estimate_market_volatility(yield_data)
        }
        
        planning_prompt = f"""
        You are an elite AI agent planning a DeFi yield optimization strategy.
        
        CONTEXT:
        {json.dumps(planning_context, indent=2)}
        
        AGENT GOALS:
        - Primary: {self.goals["primary"]}
        - Secondary: {self.goals["secondary"]}
        
        AVAILABLE TOOLS:
        {list(self.tools.keys())}
        
        Create a strategic execution plan. What tools should you use and in what order?
        
        Respond with JSON:
        {{
            "execution_steps": [
                {{
                    "step": 1,
                    "tool": "fetch_live_market_data",
                    "objective": "Get current market conditions",
                    "priority": "high",
                    "expected_outcome": "Market sentiment and price analysis"
                }}
            ],
            "risk_management_approach": "Description of risk approach",
            "success_criteria": ["criterion1", "criterion2"],
            "contingency_plans": ["plan1", "plan2"]
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(planning_prompt, "strategic planning")
            plan_data = self._extract_json_from_response(response)
            
            if plan_data and "execution_steps" in plan_data:
                self.current_plan = plan_data
                return plan_data["execution_steps"]
                
        except Exception as e:
            print(f"‚ö†Ô∏è Agent planning failed: {e}")
        
        # Production-ready fallback plan
        return [
            {"step": 1, "tool": "fetch_live_market_data", "objective": "market_assessment"},
            {"step": 2, "tool": "get_real_time_yields", "objective": "yield_analysis"},
            {"step": 3, "tool": "analyze_protocol_health", "objective": "risk_evaluation"},
            {"step": 4, "tool": "calculate_risk_metrics", "objective": "risk_quantification"},
            {"step": 5, "tool": "analyze_gas_optimization", "objective": "gas_analysis"},
            {"step": 6, "tool": "run_monte_carlo_simulation", "objective": "outcome_simulation"}
        ]

    async def _execute_analysis_plan(self, execution_plan: List[Dict]) -> Dict:
        """Execute the agent's analysis plan using production tools"""
        
        analysis_results = {}
        
        for step in execution_plan:
            tool_name = step.get("tool")
            objective = step.get("objective", "analysis")
            
            if tool_name in self.tools:
                print(f"üîß Agent executing: {tool_name} -> {objective}")
                
                try:
                    # Execute tool with current context
                    if tool_name == "validate_strategy_quality":
                        # Special handling for validation tool
                        tool_result = await self.tools[tool_name].function(
                            context=self.execution_context,
                            objective=objective,
                            strategy=self.execution_context.get("current_strategy"),
                            analysis_results=analysis_results
                        )
                    else:
                        tool_result = await self.tools[tool_name].function(
                            context=self.execution_context,
                            objective=objective
                        )
                    
                    analysis_results[tool_name] = tool_result
                    
                    # Update execution context
                    self.execution_context[tool_name] = tool_result
                    
                    # Agent reflection after each tool
                    should_continue = await self._agent_reflection(step, tool_result)
                    if not should_continue:
                        print("üõë Agent decided to halt execution")
                        break
                        
                except Exception as e:
                    print(f"‚ùå Tool {tool_name} failed: {e}")
                    analysis_results[tool_name] = {"error": str(e)}
        
        return analysis_results

    async def _synthesize_strategy(
        self, capital: float, risk_profile: RiskProfile, analysis_results: Dict
    ) -> Dict:
        """Agent synthesizes all analysis into a coherent strategy"""
        
        synthesis_prompt = f"""
        You are an elite AI agent synthesizing analysis results into an optimal DeFi strategy.
        
        INVESTMENT PARAMETERS:
        - Capital: ${capital:,}
        - Risk Profile: {risk_profile.value}
        
        AGENT ANALYSIS RESULTS:
        {json.dumps(analysis_results, default=str, indent=2)}
        
        AGENT GOALS:
        - Primary: {self.goals["primary"]}
        - Success Metrics: {self.goals["success_metrics"]}
        
        AGENT MEMORY (Previous Learnings):
        {json.dumps(self.memory.get("learned_patterns", {}), default=str)}
        
        Synthesize all analysis into an optimal strategy. Think step-by-step:
        1. What did the market analysis reveal?
        2. Which opportunities align with the risk profile?
        3. How should risk be distributed?
        4. What are the key success factors?
        
        RESPOND WITH ONLY VALID JSON IN THIS EXACT FORMAT:
        {{
            "strategy_reasoning": {{
                "market_assessment": "Your market analysis conclusion",
                "opportunity_evaluation": "Best opportunities identified",
                "risk_distribution": "How you're managing risk",
                "optimization_logic": "Your optimization approach"
            }},
            "allocations": [
                {{
                    "asset": "USDC",
                    "protocol": "aave-v3",
                    "percentage": 40.0,
                    "expected_yield": 8.5,
                    "risk_score": 0.2,
                    "strategic_rationale": "Why this allocation"
                }}
            ],
            "portfolio_metrics": {{
                "expected_yield": 9.2,
                "risk_score": 0.3,
                "diversification_score": 0.8,
                "sharpe_ratio_estimate": 1.8
            }},
            "monitoring_triggers": ["trigger1", "trigger2"],
            "agent_confidence": 0.85
        }}
        
        IMPORTANT: Return ONLY the JSON object, no explanations or markdown.
        """
        
        try:
            print("üîÑ Agent attempting strategy synthesis...")
            response = await self._call_ai_with_retry(synthesis_prompt, "strategy synthesis")
            
            if not response:
                print("‚ùå Empty response from Groq API during strategy synthesis")
                return self._create_fallback_strategy(capital, risk_profile, analysis_results)
            
            print(f"üìù Raw synthesis response: {response[:200]}...")
            
            strategy_data = self._extract_json_from_response(response)
            
            if strategy_data and self._validate_strategy_structure(strategy_data):
                print("‚úÖ Strategy synthesis successful")
                return strategy_data
            else:
                print("‚ö†Ô∏è Invalid strategy structure from AI")
                return self._create_fallback_strategy(capital, risk_profile, analysis_results)
                
        except Exception as e:
            print(f"‚ùå Strategy synthesis failed: {e}")
            return self._create_fallback_strategy(capital, risk_profile, analysis_results)

    def _validate_strategy_structure(self, strategy: Dict) -> bool:
        """Validate that strategy has required structure"""
        required_keys = ["allocations", "portfolio_metrics", "agent_confidence"]
        
        if not all(key in strategy for key in required_keys):
            return False
        
        # Validate allocations
        allocations = strategy.get("allocations", [])
        if not allocations or not isinstance(allocations, list):
            return False
            
        for alloc in allocations:
            required_alloc_keys = ["asset", "percentage", "expected_yield", "risk_score"]
            if not all(key in alloc for key in required_alloc_keys):
                return False
                
        # Validate portfolio metrics
        portfolio_metrics = strategy.get("portfolio_metrics", {})
        if not isinstance(portfolio_metrics, dict):
            return False
            
        return True

    async def _refine_strategy(self, strategy: Dict, quality_check: Dict, analysis_results: Dict) -> Dict:
        """Agent refines its strategy based on quality assessment"""
        
        refinement_prompt = f"""
        You are an elite AI agent refining your strategy based on quality assessment.
        
        CURRENT STRATEGY:
        {json.dumps(strategy, default=str, indent=2)}
        
        QUALITY ISSUES IDENTIFIED:
        {json.dumps(quality_check.get("identified_weaknesses", []))}
        
        IMPROVEMENT SUGGESTIONS:
        {json.dumps(quality_check.get("improvement_suggestions", []))}
        
        Refine your strategy to address all identified issues:
        
        Respond with JSON (same format as original strategy):
        {{
            "strategy_reasoning": {{
                "refinement_rationale": "What you changed and why",
                "improvements_made": ["improvement1", "improvement2"]
            }},
            "allocations": [refined allocations],
            "portfolio_metrics": {{improved metrics}},
            "agent_confidence": 0.90
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(refinement_prompt, "strategy refinement")
            refined_strategy = self._extract_json_from_response(response)
            
            if refined_strategy:
                return refined_strategy
                
        except Exception as e:
            print(f"‚ö†Ô∏è Strategy refinement failed: {e}")
        
        return strategy  # Return original if refinement fails

    async def _update_agent_memory(self, strategy: Dict, analysis_results: Dict, quality_check: Dict):
        """Update agent memory with learnings"""
        
        memory_entry = {
            "timestamp": datetime.now().isoformat(),
            "strategy": strategy,
            "analysis_results": analysis_results,
            "quality_assessment": quality_check,
            "performance_expectation": strategy.get("portfolio_metrics", {}).get("expected_yield", 0)
        }
        
        self.memory["decision_history"].append(memory_entry)
        
        # Extract patterns for learning
        if quality_check.get("overall_grade") in ["A", "B"]:
            # Learn from successful strategies
            success_pattern = {
                "allocation_approach": strategy.get("strategy_reasoning", {}).get("optimization_logic", ""),
                "risk_management": strategy.get("strategy_reasoning", {}).get("risk_distribution", ""),
                "market_conditions": analysis_results.get("fetch_live_market_data", {})
            }
            
            self.memory["learned_patterns"][datetime.now().isoformat()] = success_pattern
        
        print(f"üß† Agent memory updated with new learnings")

    async def _agent_reflection(self, step: Dict, result: Any) -> bool:
        """Agent reflects on each step and decides whether to continue"""
        
        reflection_prompt = f"""
        You are an AI agent reflecting on your execution step.
        
        STEP EXECUTED:
        {json.dumps(step, indent=2)}
        
        RESULT:
        {json.dumps(result, default=str, indent=2)}
        
        EXECUTION CONTEXT:
        {json.dumps(self.execution_context, default=str, indent=2)}
        
        Should you continue with the plan or make adjustments?
        
        Respond with JSON:
        {{
            "continue_execution": true/false,
            "reflection": "Your analysis of this step",
            "adjustments_needed": "Any plan adjustments",
            "confidence_in_progress": 0.0-1.0
        }}
        """
        
        try:
            response = await self._call_ai_with_retry(reflection_prompt, "agent reflection")
            reflection_data = self._extract_json_from_response(response)
            
            if reflection_data:
                continue_execution = reflection_data.get("continue_execution", True)
                print(f"ü§î Agent reflection: {reflection_data.get('reflection', 'Continuing...')}")
                return continue_execution
                
        except Exception as e:
            print(f"‚ö†Ô∏è Agent reflection failed: {e}")
        
        return True  # Continue by default

    # MODEL FAILOVER LOGIC
    async def _test_model_availability(self, model_name: str) -> bool:
        """Test if a model is available and working"""
        try:
            if model_name.startswith("openai-"):
                # Test OpenAI model
                if not self.openai_client:
                    from openai import AsyncOpenAI
                    self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                
                actual_model = model_name.replace("openai-", "")
                response = await self.openai_client.chat.completions.create(
                    model=actual_model,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                return response.choices[0].message.content is not None
            else:
                # Test Groq model
                response = await self.client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=10
                )
                return response.choices[0].message.content is not None
                
        except Exception as e:
            error_msg = str(e).lower()
            if "rate limit" in error_msg or "quota" in error_msg:
                print(f"‚ùå {model_name}: Rate limit exceeded")
                self.model_status[model_name] = {"status": "rate_limited", "error": str(e)}
            elif "not found" in error_msg or "invalid" in error_msg:
                print(f"‚ùå {model_name}: Model not available")
                self.model_status[model_name] = {"status": "unavailable", "error": str(e)}
            else:
                print(f"‚ùå {model_name}: Other error - {e}")
                self.model_status[model_name] = {"status": "error", "error": str(e)}
            return False

    async def _find_working_model(self) -> str:
        """Find the first working model from the list"""
        for model in self.available_models:
            if model in self.model_status:
                status = self.model_status[model]["status"]
                if status in ["rate_limited", "unavailable"]:
                    continue
            
            print(f"üß™ Testing model: {model}")
            if await self._test_model_availability(model):
                print(f"‚úÖ Model {model} is working")
                self.current_model = model
                self.model_status[model] = {"status": "working", "last_used": datetime.now().isoformat()}
                return model
        
        raise Exception("No working models available")

    async def _call_ai_with_retry(self, prompt: str, task: str, max_retries: int = 3) -> str:
        """Call AI with intelligent model failover"""
        
        # Find working model if we don't have one
        if not self.current_model:
            try:
                self.current_model = await self._find_working_model()
            except Exception as e:
                raise Exception(f"No AI models available: {e}")
        
        for attempt in range(max_retries):
            try:
                # Try current model
                response = await self._make_ai_call(prompt, task, self.current_model)
                if response:
                    return response
                    
            except Exception as e:
                error_msg = str(e).lower()
                
                if "rate limit" in error_msg or "quota" in error_msg:
                    print(f"üîÑ {self.current_model} hit rate limit, switching models...")
                    self.model_status[self.current_model] = {"status": "rate_limited", "error": str(e)}
                    
                    # Find next working model
                    try:
                        self.current_model = await self._find_working_model()
                        print(f"‚úÖ Switched to {self.current_model}")
                        continue  # Retry with new model
                    except Exception:
                        if attempt == max_retries - 1:
                            raise Exception("All models exhausted due to rate limits")
                        else:
                            await asyncio.sleep(60)  # Wait 1 minute before trying again
                            continue
                
                elif attempt == max_retries - 1:
                    raise e
                else:
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
        
        raise Exception(f"Failed to get AI response after {max_retries} attempts")

    async def _make_ai_call(self, prompt: str, task: str, model: str) -> str:
        """Make the actual AI API call"""
        
        messages = [
            {"role": "system", "content": f"You are an elite AI agent performing {task}. Respond with valid JSON only."},
            {"role": "user", "content": prompt}
        ]
        
        if model.startswith("openai-"):
            # OpenAI API call
            if not self.openai_client:
                from openai import AsyncOpenAI
                self.openai_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            actual_model = model.replace("openai-", "")
            response = await asyncio.wait_for(
                self.openai_client.chat.completions.create(
                    model=actual_model,
                    messages=messages,
                    temperature=0.1,
                    max_tokens=2000
                ),
                timeout=30.0
            )
        else:
            # Groq API call
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=0.1,
                    max_tokens=2000
                ),
                timeout=30.0
            )
        
        if response and response.choices and response.choices[0].message.content:
            return response.choices[0].message.content.strip()
        
        return None

    async def _generate_analysis_plan(self, capital: float, risk_profile: RiskProfile, yield_data: List[YieldData], gas_data: Dict) -> str:
        """Generate comprehensive analysis plan using AI with failover"""
        
        prompt = f"""
        You are an elite DeFi yield optimization agent. Generate a comprehensive analysis plan for:
        
        CAPITAL: ${capital:,}
        RISK PROFILE: {risk_profile.value}
        AVAILABLE OPPORTUNITIES: {len(yield_data)} protocols
        
        YIELD DATA SUMMARY:
        {self._format_yield_data_for_prompt(yield_data)}
        
        GAS CONDITIONS: {gas_data.get('standard', 'unknown')} gwei
        
        Create a detailed analysis plan covering:
        1. Risk assessment approach
        2. Yield optimization strategy
        3. Gas cost considerations
        4. Diversification requirements
        5. Market condition analysis
        
        Keep it concise but comprehensive.
        """
        
        return await self._call_ai_with_retry(prompt, "analysis_plan_generation")
    
    async def _execute_risk_analysis(self, capital: float, risk_profile: RiskProfile, yield_data: List[YieldData]) -> Dict:
        """Execute risk analysis using AI with failover"""
        
        prompt = f"""
        Perform detailed risk analysis for DeFi yield optimization:
        
        CAPITAL: ${capital:,}
        RISK PROFILE: {risk_profile.value}
        
        PROTOCOLS TO ANALYZE:
        {self._format_yield_data_for_prompt(yield_data)}
        
        Analyze each protocol for:
        1. Smart contract risk (0-1 score)
        2. Liquidity risk (0-1 score)
        3. Impermanent loss risk (0-1 score)
        4. Protocol reputation (0-1 score)
        5. Overall risk score (0-1 score)
        
        Return analysis in this exact JSON format:
        {{
            "protocol_risks": {{
                "protocol_name": {{
                    "smart_contract_risk": 0.0,
                    "liquidity_risk": 0.0,
                    "impermanent_loss_risk": 0.0,
                    "protocol_reputation": 0.0,
                    "overall_risk": 0.0,
                    "reasoning": "explanation"
                }}
            }},
            "market_sentiment": "bullish/bearish/neutral",
            "recommended_max_allocation": 0.0
        }}
        """
        
        response = await self._call_ai_with_retry(prompt, "risk_analysis")
        return self._parse_json_response(response)
    
    async def _generate_yield_strategy(self, capital: float, risk_profile: RiskProfile, yield_data: List[YieldData], risk_analysis: Dict) -> Dict:
        """Generate yield optimization strategy using AI with failover"""
        
        prompt = f"""
        Generate optimal yield strategy based on risk analysis:
        
        CAPITAL: ${capital:,}
        RISK PROFILE: {risk_profile.value}
        
        AVAILABLE PROTOCOLS:
        {self._format_yield_data_for_prompt(yield_data)}
        
        RISK ANALYSIS RESULTS:
        {self._format_risk_analysis_for_prompt(risk_analysis)}
        
        Generate allocation strategy considering:
        1. Risk-adjusted returns
        2. Diversification requirements
        3. Capital efficiency
        4. Yield sustainability
        5. Market conditions
        
        Return strategy in this exact JSON format:
        {{
            "allocations": [
                {{
                    "asset": "protocol_name",
                    "percentage": 0.0,
                    "expected_yield": 0.0,
                    "risk_score": 0.0,
                    "reasoning": "explanation"
                }}
            ],
            "total_expected_yield": 0.0,
            "total_risk_score": 0.0,
            "strategy_confidence": 0.0
        }}
        """
        
        response = await self._call_ai_with_retry(prompt, "yield_strategy_generation")
        return self._parse_json_response(response)
    
    async def _optimize_gas_strategy(self, allocations: List[Dict], gas_data: Dict) -> Dict:
        """Optimize gas strategy using AI with failover"""
        
        prompt = f"""
        Optimize gas strategy for DeFi allocations:
        
        PROPOSED ALLOCATIONS:
        {json.dumps(allocations, indent=2)}
        
        CURRENT GAS CONDITIONS:
        - Standard: {gas_data.get('standard', 'unknown')} gwei
        - Fast: {gas_data.get('fast', 'unknown')} gwei
        - Instant: {gas_data.get('instant', 'unknown')} gwei
        
        Optimize for:
        1. Transaction cost efficiency
        2. Timing recommendations
        3. Batch transaction opportunities
        4. Gas price predictions
        
        Return optimization in this exact JSON format:
        {{
            "recommended_gas_price": 0.0,
            "estimated_total_cost": 0.0,

            "timing_recommendation": "immediate/wait_for_lower_gas/schedule_for_off_peak",
            "batch_opportunities": ["list", "of", "protocols"],
            "gas_optimization_score": 0.0
        }}
        """
        
        response = await self._call_ai_with_retry(prompt, "gas_optimization")
        return self._parse_json_response(response)
    
    async def _generate_final_recommendation(self, capital: float, strategy: Dict, gas_optimization: Dict, risk_analysis: Dict) -> RecommendationResponse:
        """Generate final recommendation using AI with failover"""
        
        prompt = f"""
        Generate final investment recommendation:
        
        CAPITAL: ${capital:,}
        STRATEGY: {json.dumps(strategy, indent=2)}
        GAS OPTIMIZATION: {json.dumps(gas_optimization, indent=2)}
        RISK ANALYSIS: {json.dumps(risk_analysis, indent=2)}
        
        Provide final recommendation with:
        1. Refined allocation percentages
        2. Risk-adjusted expected yields
        3. Confidence scoring
        4. Implementation guidance
        
        Return recommendation in this exact JSON format:
        {{
            "final_allocations": [
                {{
                    "asset": "protocol_name",
                    "percentage": 0.0,
                    "expected_yield": 0.0,
                    "risk_score": 0.0
                }}
            ],
            "total_expected_yield": 0.0,
            "total_risk_score": 0.0,
            "confidence_score": 0.0,
            "implementation_notes": "guidance text"
        }}
        """
        
        response = await self._call_ai_with_retry(prompt, "final_recommendation")
        final_data = self._parse_json_response(response)
        
        # Convert to RecommendationResponse
        allocations = []
        for alloc in final_data.get("final_allocations", []):
            allocations.append(AllocationItem(
                asset=alloc["asset"],
                percentage=alloc["percentage"],
                expected_yield=alloc["expected_yield"],
                risk_score=alloc["risk_score"]
            ))
        
        return RecommendationResponse(
            timestamp=datetime.now(),
            capital=capital,
            risk_profile=RiskProfile.MODERATE,  # This should be passed in
            allocations=allocations,
            total_expected_yield=final_data.get("total_expected_yield", 0.0),
            total_risk_score=final_data.get("total_risk_score", 0.0),
            gas_cost_estimate=gas_optimization.get("estimated_total_cost", 50.0),
            confidence_score=final_data.get("confidence_score", 0.8)
        )
